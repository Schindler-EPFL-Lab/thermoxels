@article{mollyn2022samosa,
  journal   = {Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies},
  title     = {SAMoSA: Sensing activities with motion and subsampled audio},
  author    = {Mollyn, Vimal and Ahuja, Karan and Verma, Dhruv and Harrison, Chris and Goel, Mayank},
  volume    = {6},
  number    = {3},
  year      = {2022},
  pages     = {1--19},
  publisher = {ACM New York, NY, USA}
}

@inproceedings{zhang2012usc,
  title     = {USC-HAD A daily activity dataset for ubiquitous activity recognition using wearable sensors},
  pages     = {1036--1043},
  author    = {Zhang, Mi and Sawchuk, Alexander A},
  year      = {2012},
  booktitle = {Proceedings of the 2012 ACM conference on ubiquitous computing}
}

@article{weiss2019wisdm,
  author  = {Weiss, Gary M},
  pages   = {133190--133202},
  year    = {2019},
  title   = {Wisdm smartphone and smartwatch activity and biometrics dataset},
  journal = {UCI Machine Learning Repository: WISDM Smartphone and Smartwatch Activity and Biometrics Dataset Data Set},
  volume  = {7}
}

@article{hassan2025Thermo,
  month     = {May},
  year      = {2025},
  author    = {Hassan, Mariam and Forest, Florent and Fink, Olga and Mielle, Malcolm},
  journal   = {Advanced Engineering Informatics},
  doi       = {10.1016/j.aei.2025.103345},
  title     = {ThermoNeRF: A multimodal Neural Radiance Field for joint RGB-thermal novel view synthesis of building facades},
  url       = {http://dx.doi.org/10.1016/j.aei.2025.103345},
  publisher = {Elsevier BV},
  pages     = {103345},
  issn      = {1474-0346},
  volume    = {65}
}

@inproceedings{10.1007/978-3-031-73383-3_15,
  author    = {Chen, Qian
               and Shu, Shihao
               and Bai, Xiangzhi},
  editor    = {Leonardis, Ale{\v{s}}
               and Ricci, Elisa
               and Roth, Stefan
               and Russakovsky, Olga
               and Sattler, Torsten
               and Varol, G{\"u}l},
  title     = {Thermal3D-GS: Physics-Induced 3D Gaussians forÂ Thermal Infrared Novel-View Synthesis},
  booktitle = {Computer Vision -- ECCV 2024},
  year      = {2025},
  publisher = {Springer Nature Switzerland},
  address   = {Cham},
  pages     = {253--269},
  abstract  = {Novel-view synthesis based on visible light has been extensively studied. In comparison to visible light imaging, thermal infrared imaging offers the advantage of all-weather imaging and strong penetration, providing increased possibilities for reconstruction in nighttime and adverse weather scenarios. However, thermal infrared imaging is influenced by physical characteristics such as atmospheric transmission effects and thermal conduction, hindering the precise reconstruction of intricate details in thermal infrared scenes, manifesting as issues of floaters and indistinct edge features in synthesized images. To address these limitations, this paper introduces a physics-induced 3D Gaussian splatting method named Thermal3D-GS. Thermal3D-GS begins by modeling atmospheric transmission effects and thermal conduction in three-dimensional media using neural networks. Additionally, a temperature consistency constraint is incorporated into the optimization objective to enhance the reconstruction accuracy of thermal infrared images. Furthermore, to validate the effectiveness of our method, the first large-scale benchmark dataset for this field named Thermal Infrared Novel-view Synthesis Dataset (TI-NSD) is created. This dataset comprises 20 authentic thermal infrared video scenes, covering indoor, outdoor, and UAV(Unmanned Aerial Vehicle) scenarios, totaling 6,664 frames of thermal infrared image data. Based on this dataset, this paper experimentally verifies the effectiveness of Thermal3D-GS. The results indicate that our method outperforms the baseline method with a 3.03 dB improvement in PSNR and significantly addresses the issues of floaters and indistinct edge features present in the baseline method. Our dataset and codebase will be released in Thermal3DGS.},
  isbn      = {978-3-031-73383-3}
}

@inproceedings{fridovich2022plenoxels,
  title     = {Plenoxels: Radiance fields without neural networks},
  author    = {Fridovich-Keil, Sara and Yu, Alex and Tancik, Matthew and Chen, Qinhong and Recht, Benjamin and Kanazawa, Angjoo},
  booktitle = {Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages     = {5501--5510},
  year      = {2022}
}

